{
  "hash": "a94358425a61beee8eb989a42757f894",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Econometrics - Lecture 7\"\nsubtitle: \"Transformations and Non-Linear Models\"\nauthor: \"Logan Kelly Ph.D.\"\ndate: \"January 28, 2025\"\n---\n\n\n\n## Introduction\n\n- This lecture explores regression models that use transformations of variables to capture non-linear relationships.\n- Focus areas:\n  - Linear-Log Model\n  - Polynomial Models\n  - Log-Linear Model\n  - Log-Log Model\n- Each approach can improve model fit and interpretability, especially when the relationship between the dependent and independent variables is not purely linear.\n\n## Key Concepts\n\n- Transformations can address:\n  - Curvilinear relationships (polynomial models).\n  - Percentage changes (log transformations).\n  - Diminishing returns or growth patterns (log-log models).\n\n- R-squared considerations:\n  - Standard R-squared is straightforward for models in the original (untransformed) scale.\n  - Models involving logs may use alternative fit measures (e.g., adjusted R-squared or pseudo R-squared) depending on context.\n\n## Linear-Log Model\n\n- Structure:\n  - Dependent variable (Y) is in its original form.\n  - Independent variable (X) is transformed using the natural log.\n  - Model form:  \n    $$\n    Y = \\beta_0 + \\beta_1 \\ln(X) + \\epsilon\n    $$\n\n- Interpretation:\n  - $\\beta_1$ indicates the change in $Y$ for a 1% change in $X$, holding other factors constant.\n  - Useful when the effect of $X$ on $Y$ is expected to diminish as $X$ grows.\n\n- Example with `mtcars`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Linear-Log example: mpg vs ln(wt)\ndata <- mtcars\nmodel_linlog <- lm(mpg ~ log(wt), data = data)\nsummary(model_linlog)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = mpg ~ log(wt), data = data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.7440 -2.0954 -0.3672  1.0709  6.6150 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   39.257      1.758   22.32  < 2e-16 ***\nlog(wt)      -17.086      1.510  -11.31 2.39e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.669 on 30 degrees of freedom\nMultiple R-squared:  0.8101,\tAdjusted R-squared:  0.8038 \nF-statistic:   128 on 1 and 30 DF,  p-value: 2.391e-12\n```\n\n\n:::\n:::\n\n\n\n## Polynomial Models\n\n- Structure:\n  - Polynomial terms capture curvature in the relationship.\n  - Common example: quadratic model.  \n    $$\n    Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\epsilon\n    $$\n\n- Interpretation:\n  - $\\beta_1$ is the linear term, $\\beta_2$ captures curvature.\n  - A positive $\\beta_2$ indicates a U-shaped curve, negative indicates an inverted U-shape.\n\n- Example with `mtcars`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Polynomial example: mpg vs wt (including wt^2)\nmodel_poly <- lm(mpg ~ wt + I(wt^2), data = data)\nsummary(model_poly)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = mpg ~ wt + I(wt^2), data = data)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-3.483 -1.998 -0.773  1.462  6.238 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  49.9308     4.2113  11.856 1.21e-12 ***\nwt          -13.3803     2.5140  -5.322 1.04e-05 ***\nI(wt^2)       1.1711     0.3594   3.258  0.00286 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.651 on 29 degrees of freedom\nMultiple R-squared:  0.8191,\tAdjusted R-squared:  0.8066 \nF-statistic: 65.64 on 2 and 29 DF,  p-value: 1.715e-11\n```\n\n\n:::\n:::\n\n\n\n## Log-Linear Model\n\n- Structure:\n  - Dependent variable (Y) is transformed using the natural log.\n  - Independent variables remain in original form.\n  - Model form:  \n    $$\n    \\ln(Y) = \\beta_0 + \\beta_1 X + \\epsilon\n    $$\n\n- Interpretation:\n  - $\\beta_1$ represents the approximate percentage change in $Y$ for a one-unit change in $X$.\n  - Often used when $Y$ grows exponentially, such as with population or monetary variables.\n\n- Example with `mtcars`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Log-Linear example: ln(mpg) vs wt\nmodel_loglin <- lm(log(mpg) ~ wt, data = data)\nsummary(model_loglin)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = log(mpg) ~ wt, data = data)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.210346 -0.085932 -0.006136  0.061335  0.308623 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  3.83191    0.08396   45.64  < 2e-16 ***\nwt          -0.27178    0.02500  -10.87 6.31e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1362 on 30 degrees of freedom\nMultiple R-squared:  0.7976,\tAdjusted R-squared:  0.7908 \nF-statistic: 118.2 on 1 and 30 DF,  p-value: 6.31e-12\n```\n\n\n:::\n:::\n\n\n\n## Log-Log Model\n\n- Structure:\n  - Both $Y$ and $X$ are in natural log form.\n  - Model form:  \n    $$\n    \\ln(Y) = \\beta_0 + \\beta_1 \\ln(X) + \\epsilon\n    $$\n\n- Interpretation:\n  - $\\beta_1$ is the elasticity of $Y$ with respect to $X$.\n  - A 1% change in $X$ is associated with a $\\beta_1\\%$ change in $Y$.\n\n- Example with `mtcars`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Log-Log example: ln(mpg) vs ln(wt)\nmodel_loglog <- lm(log(mpg) ~ log(wt), data = data)\nsummary(model_loglog)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = log(mpg) ~ log(wt), data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.18141 -0.10681 -0.02125  0.08109  0.26930 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  3.90181    0.08790   44.39  < 2e-16 ***\nlog(wt)     -0.84182    0.07549  -11.15 3.41e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1334 on 30 degrees of freedom\nMultiple R-squared:  0.8056,\tAdjusted R-squared:  0.7992 \nF-statistic: 124.4 on 1 and 30 DF,  p-value: 3.406e-12\n```\n\n\n:::\n:::\n\n\n\n## Case Illustration and Comparisons\n\n- Fitting various models helps determine:\n  - Which transformation best explains the data.\n  - How to interpret relationships in terms of levels, changes, or elasticities.\n- Model comparison:\n  - Look at adjusted R-squared, AIC, or BIC to evaluate model fit.\n  - Review residuals and diagnostic plots for pattern detection.\n\n## Conclusion\n\n- Transformations can capture important non-linear patterns.\n- Linear-log and log-linear models focus on percentage changes.\n- Polynomial models capture curvilinear effects.\n- Log-log models estimate elasticity relationships.\n\n- Takeaways:\n  - Choose transformations to match theoretical expectations.\n  - Always interpret coefficients in the transformed context.\n  - Use diagnostics (residual plots, fit indices) to compare models.\n",
    "supporting": [
      "Lecture_M01-L07_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}