{
  "hash": "66f8a2e9e8f1663185c7a7977b100a44",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Econometrics - Lecture 2\"\nsubtitle: \"Simple Linear Regression Basics\"\nauthor: \"Logan Kelly, Ph.D.\"\ndate: \"January 26, 2025\"\n---\n\n\n\n## Introduction\n\nIn this lecture, we delve into the basics of simple linear regression, focusing on the foundational idea that one independent variable $x$ can be used to predict a single dependent variable $y$. We will discuss the model setup (equation of a line), the interpretation of parameters (slope and intercept), and a basic coding example in R to illustrate how to estimate a simple regression model using `lm()`.\n\n## Key Concepts\n\n- Model Setup\n- Understanding Parameters\n- Reading and Writing R Code\n\n## Theoretical Discussion\n\n### Model Setup\n\n- **Equation of a Line**  \n  The simple linear regression model is expressed as:  \n  $$y = \\beta_0 + \\beta_1 x + \\varepsilon$$  \n  where:\n  - $y$ is the dependent variable.\n  - $x$ is the independent variable.\n  - $\\beta_0$ is the intercept.\n  - $\\beta_1$ is the slope coefficient.\n  - $\\varepsilon$ is the error term.\n\n\n### Understanding Parameters\n\n- **$\\beta_0$ (Intercept)**  \n  - Represents the expected value of $y$ when $x = 0$.\n  - Indicates the baseline level of the dependent variable.\n  \n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Lecture_M01-L02_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\n  \n- **$\\beta_1$ (Slope)**  \n  - Measures the expected change in $y$ for a one-unit change in $x$.\n  - Indicates the strength and direction of the relationship between $x$ and $y$.\n\n- **$\\varepsilon$ (Error Term)**  \n  - Captures all other factors affecting $y$ that are not included in the model.\n  - Assumed to have a mean of zero:  \n    $$\\mathrm{E}(\\varepsilon) = 0$$  \n  - Represents random variability in the dependent variable.\n\n### Reading and Writing R Code\n\n- **Estimating a Simple Linear Regression Model in R**  \n  The `lm()` function is used to fit linear models. Below is a basic example:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Example dataset\ndata(mtcars)\n\n# Fit a simple linear regression model\nmodel <- lm(mpg ~ wt, data = mtcars)\n\n# View the summary of the model\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = mpg ~ wt, data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.5432 -2.3647 -0.1252  1.4096  6.8727 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  37.2851     1.8776  19.858  < 2e-16 ***\nwt           -5.3445     0.5591  -9.559 1.29e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.046 on 30 degrees of freedom\nMultiple R-squared:  0.7528,\tAdjusted R-squared:  0.7446 \nF-statistic: 91.38 on 1 and 30 DF,  p-value: 1.294e-10\n```\n\n\n:::\n:::\n\n\n\n- **Interpreting the Output**  \n  - **Coefficients**: Estimates of $\\beta_0$ and $\\beta_1$.\n  - **R-squared**: Proportion of variance in $y$ explained by $x$.\n  - **p-values**: Test the null hypothesis that the coefficient is equal to zero.\n\n## Case Study\n\nConsider a dataset examining the relationship between **advertising expenditures** (in thousands of dollars) and **monthly sales** (in thousands of units). Suppose we have the following R code to estimate a simple linear regression:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load_gh(\"ccolonescu/PoEdata\")\npacman::p_load(\"jtools\")\ndata(food)\n\n# Fit a simple linear regression model\nmodel <- lm(food_exp ~ income, data = food)\n\n# View the summary\nsumm(model)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<tbody>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> Observations </td>\n   <td style=\"text-align:right;\"> 40 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> Dependent variable </td>\n   <td style=\"text-align:right;\"> food_exp </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> Type </td>\n   <td style=\"text-align:right;\"> OLS linear regression </td>\n  </tr>\n</tbody>\n</table> <table class=\"table table-striped table-hover table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<tbody>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> F(1,38) </td>\n   <td style=\"text-align:right;\"> 23.79 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> R² </td>\n   <td style=\"text-align:right;\"> 0.39 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> Adj. R² </td>\n   <td style=\"text-align:right;\"> 0.37 </td>\n  </tr>\n</tbody>\n</table> <table class=\"table table-striped table-hover table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;border-bottom: 0;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> Est. </th>\n   <th style=\"text-align:right;\"> S.E. </th>\n   <th style=\"text-align:right;\"> t val. </th>\n   <th style=\"text-align:right;\"> p </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> (Intercept) </td>\n   <td style=\"text-align:right;\"> 83.42 </td>\n   <td style=\"text-align:right;\"> 43.41 </td>\n   <td style=\"text-align:right;\"> 1.92 </td>\n   <td style=\"text-align:right;\"> 0.06 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> income </td>\n   <td style=\"text-align:right;\"> 10.21 </td>\n   <td style=\"text-align:right;\"> 2.09 </td>\n   <td style=\"text-align:right;\"> 4.88 </td>\n   <td style=\"text-align:right;\"> 0.00 </td>\n  </tr>\n</tbody>\n<tfoot><tr><td style=\"padding: 0; \" colspan=\"100%\">\n<sup></sup> Standard errors: OLS</td></tr></tfoot>\n</table>\n`````\n:::\n:::\n\n\n\n- **Interpretation**  \n  - $\\hat{\\beta}_0$: Predicted sales when advertising expenditures are zero (the intercept).\n  - $\\hat{\\beta}_1$: Average change in sales (in thousands of units) for each additional thousand dollars in advertising.\n\n- **Assessing Model Fit**  \n  - **R-squared**: Indicates how well the independent variable explains the variation in the dependent variable.\n  - **Residual Analysis**: Check for patterns that might suggest violations of regression assumptions.\n\n## Conclusion\n\n- A simple linear regression assumes a direct, linear relationship between one independent variable and the dependent variable.\n- OLS estimation finds the best-fitting line by minimizing the sum of squared errors, producing unbiased estimates of slope and intercept under the classic assumptions.\n- Practical coding in R typically involves `lm()`, which quickly estimates parameters and provides summary statistics for model evaluation.\n",
    "supporting": [
      "Lecture_M01-L02_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}