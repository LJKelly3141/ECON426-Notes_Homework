{
  "hash": "fb0c2f1e403c3c318ac65e0bf99dcf9e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Econometrics - Lecture 3\"\nsubtitle: \"Interpreting Regression Output\"\nauthor: \"Logan Kelly, Ph.D.\"\ndate: \"January 25, 2025\"\n---\n\n\n\n## Introduction\n\nUnderstanding the output of a regression analysis is crucial for making informed decisions based on data. In this lecture, we will explore how to interpret the various components of regression output, including coefficients, R-squared, p-values, and confidence intervals. Additionally, we will visualize regression results by plotting data with a negative correlation and overlaying two best fit lines: one using Ordinary Least Squares (OLS) and another using OLS with the intercept restricted to zero.\n\n## Key Concepts\n\n- Components of Regression Output\n- Interpreting Coefficients\n- R-squared and Adjusted R-squared\n- Significance Levels and p-values\n- Confidence Intervals\n- Model Comparison: OLS vs. OLS with Intercept = 0\n\n## Theoretical Discussion\n\n### Components of Regression Output\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load the mtcars dataset\ndata(mtcars)\n\n# Fit a simple linear regression model\nmodel <- lm(mpg ~ wt, data = mtcars)\n\n# View the summary of the model\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = mpg ~ wt, data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.5432 -2.3647 -0.1252  1.4096  6.8727 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  37.2851     1.8776  19.858  < 2e-16 ***\nwt           -5.3445     0.5591  -9.559 1.29e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.046 on 30 degrees of freedom\nMultiple R-squared:  0.7528,\tAdjusted R-squared:  0.7446 \nF-statistic: 91.38 on 1 and 30 DF,  p-value: 1.294e-10\n```\n\n\n:::\n:::\n\n\n- **Call**: Displays the function call that generated the model.\n- **Residuals**: Summarizes the distribution of residuals (differences between observed and predicted values).\n- **Coefficients**: Estimates of $\\beta_0$ (intercept) and $\\beta_1$ (slope).\n- **Standard Errors**: Measure the variability of the coefficient estimates.\n- **t-values**: Ratio of coefficients to their standard errors, used to test hypotheses.\n- **p-values**: Indicate the probability of observing the data if the null hypothesis is true.\n- **R-squared ($R^2$)**:Proportion of variance in the dependent variable explained by the independent variable.\n- **F-statistic**: Tests the overall significance of the model.\n\n### Interpreting Coefficients\n\n- **Intercept ($\\beta_0$)**\n  - Expected value of $y$ when $x = 0$.\n- **Slope ($\\beta_1$)**\n  - Expected change in $y$ for a one-unit change in $x$.\n- **Sign**\n  - Indicates the direction of the relationship (positive or negative).\n- **t value**: The ratio of the estimate to its standard error, used to determine the significance of the coefficient.\n- **Pr(>|t|)**: The p-value corresponding to the t-value, indicating the probability of observing the data if the null hypothesis is true.\n\nBelow is the regression table obtained from `summary(model)`:\n\n|                 | Estimate | Std. Error | t value | Pr(>|t|) |\n|-----------------|----------|------------|---------|----------|\n| (Intercept)     | 37.2851  | 1.8776     | 19.856  | < 2e-16  |\n| wt              | -5.3445  | 0.5591     | -9.559  | < 2e-16  |\n\n\n### R-squared and Adjusted R-squared\n\n- **R-squared ($R^2$)**\n  - Measures the proportion of variance in the dependent variable that is predictable from the independent variable.\n- **Adjusted R-squared**\n  - Adjusts $R^2$ for the number of predictors, providing a more accurate measure when multiple variables are involved. NOT measure of goodness-of-fit!\n\n### Significance Levels and p-values\n\n- **Null Hypothesis**\n  - Typically, $\\beta_i = 0$ (no effect).\n- **p-value**\n  - Probability of obtaining test results at least as extreme as the observed results, under the assumption that the null hypothesis is correct.\n  - Low p-values (< 0.05) indicate statistical significance.\n\n### Confidence Intervals\n\n- **95% Confidence Interval**\n  - Range within which the true parameter value is expected to lie with 95% confidence.\n- **Interpretation**\n  - If the confidence interval for $\\beta_1$ does not include zero, the coefficient is statistically significant at the 5% level.\n  \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load necessary libraries\nif (!require(\"pacman\",quietly = TRUE)) install.packages(\"pacman\")\npacman::p_load(jtools)\n\n\n# View the summary of the model\nsumm(model,confint = TRUE,ci.width = 0.95)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<tbody>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> Observations </td>\n   <td style=\"text-align:right;\"> 32 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> Dependent variable </td>\n   <td style=\"text-align:right;\"> mpg </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> Type </td>\n   <td style=\"text-align:right;\"> OLS linear regression </td>\n  </tr>\n</tbody>\n</table> <table class=\"table table-striped table-hover table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<tbody>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> F(1,30) </td>\n   <td style=\"text-align:right;\"> 91.38 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> R² </td>\n   <td style=\"text-align:right;\"> 0.75 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> Adj. R² </td>\n   <td style=\"text-align:right;\"> 0.74 </td>\n  </tr>\n</tbody>\n</table> <table class=\"table table-striped table-hover table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;border-bottom: 0;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> Est. </th>\n   <th style=\"text-align:right;\"> 2.5% </th>\n   <th style=\"text-align:right;\"> 97.5% </th>\n   <th style=\"text-align:right;\"> t val. </th>\n   <th style=\"text-align:right;\"> p </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> (Intercept) </td>\n   <td style=\"text-align:right;\"> 37.29 </td>\n   <td style=\"text-align:right;\"> 33.45 </td>\n   <td style=\"text-align:right;\"> 41.12 </td>\n   <td style=\"text-align:right;\"> 19.86 </td>\n   <td style=\"text-align:right;\"> 0.00 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> wt </td>\n   <td style=\"text-align:right;\"> -5.34 </td>\n   <td style=\"text-align:right;\"> -6.49 </td>\n   <td style=\"text-align:right;\"> -4.20 </td>\n   <td style=\"text-align:right;\"> -9.56 </td>\n   <td style=\"text-align:right;\"> 0.00 </td>\n  </tr>\n</tbody>\n<tfoot><tr><td style=\"padding: 0; \" colspan=\"100%\">\n<sup></sup> Standard errors: OLS</td></tr></tfoot>\n</table>\n`````\n:::\n:::\n\n\n\n## Conclusion\n\n- Takeaway 1: Regression output includes key statistics such as coefficients, R-squared, p-values, and confidence intervals, each providing insights into the relationship between variables.\n- Takeaway 2: Understanding and interpreting these components is essential for drawing meaningful conclusions from regression analyses.\n- Takeaway 3: Visualizing regression results helps in comparing different model specifications and assessing the fit of the model to the data.\n",
    "supporting": [
      "Lecture_M01-L03_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}